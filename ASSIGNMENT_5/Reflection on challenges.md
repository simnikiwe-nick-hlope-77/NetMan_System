### **Reflection: Challenges in Translating Requirements to Use Cases and Tests**  

Developing **use cases** and **test cases** for the **NetMan_System** presented several challenges, particularly in defining functional boundaries, ensuring comprehensive coverage, and structuring test scenarios effectively. The process required careful consideration of stakeholder needs, maintaining clarity between different system components, and balancing complexity with usability.  

One of the primary difficulties was **defining clear and distinct use cases**. Since network management systems consist of many interdependent features, separating them into standalone **use cases** without unnecessary overlap was challenging. For example, **User Authentication**, **Manage User Permissions**, and **Configure Network Devices** are all related functions, yet they needed to be modeled individually while ensuring that each captured a unique system process.  

Another issue was **choosing the most critical use cases** to include in the detailed specifications. The assignment required selecting **eight key use cases**, but network security systems involve numerous operations. Prioritizing which use cases to focus on required evaluating stakeholder concerns. **Detect Intrusions** and **System Alerts & Notifications** were considered essential due to their role in security threat detection, whereas **Generate Security Reports** was included based on compliance and auditing needs.  

Writing **detailed use case specifications** also required finding the right level of depth. The descriptions had to be **detailed enough** to guide development and testing but not overly technical. For example, in **Backup & Restore Configurations**, defining **preconditions and postconditions** required balancing **technical accuracy** with **clarity**, ensuring the description was useful but not overly complex.  

When converting use cases into **test cases**, one major challenge was **ensuring full coverage of both normal operations and error handling scenarios**. Functional test cases had to validate multiple outcomes, such as **successful login, incorrect password attempts, and account lockout** in **User Authentication**. Similarly, testing **Detect Intrusions** required simulating various cyberattacks to confirm the systemâ€™s ability to detect and respond to threats.  

Defining **non-functional test cases** was also difficult, particularly in setting measurable benchmarks for performance and security. Unlike functional tests, which have clear pass/fail results, non-functional requirements needed specific performance metrics. For example, the **Performance Test for User Login Speed** required setting a **2-second response time limit**, while the **Security Test for SQL Injection Prevention** had to ensure that **malicious inputs were blocked** effectively. Establishing these criteria required research and alignment with industry standards.  

Another challenge was **maintaining traceability between requirements, use cases, and test cases**. Each test case had to be mapped to a specific **functional requirement** to ensure full validation. Some use cases, such as **Generate Security Reports**, involved multiple system components, making it harder to create **isolated test cases**. Ensuring that all required features were covered without redundant testing required careful structuring.
